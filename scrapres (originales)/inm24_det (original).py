import os
import pandas as pd
import datetime as dt
import re
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

DDIR = 'data/'

def close_cookie_banner(driver):
    """
    Intenta cerrar o remover el banner de cookies, si est√° presente,
    para evitar que interfiera con los clics.
    """
    try:
        banner = driver.find_element(By.CSS_SELECTOR, ".CookiesPolicyBanner-module__label___3IraT")
        if banner.is_displayed():
            driver.execute_script("arguments[0].remove();", banner)
            time.sleep(0.5)
    except Exception as e:
        pass

def scrape_property_detail(driver, html):
    soup = BeautifulSoup(html, "html.parser")
    data = {}

    # 1. Tipo de inmueble, √°rea, rec√°maras y estacionamientos
    h2 = soup.find("h2", class_="title-type-sup-property")
    if h2:
        tokens = [t.strip() for t in h2.get_text(separator="¬∑").split("¬∑") if t.strip()]

        data["tipo_propiedad"] = tokens[0] if len(tokens) > 0 else ""
        print("tipo_propiedad:", data["tipo_propiedad"])
        time.sleep(0.05)

        data["area_m2"] = tokens[1] if len(tokens) > 1 else ""
        print("area_m2:", data["area_m2"])
        time.sleep(0.05)

        if len(tokens) > 2:
            match = re.search(r"(\d+)", tokens[2])
            data["recamaras"] = match.group(1) if match else ""
        else:
            data["recamaras"] = ""
        print("recamaras:", data["recamaras"])
        time.sleep(0.05)

        if len(tokens) > 3:
            match = re.search(r"(\d+)", tokens[3])
            data["estacionamientos"] = match.group(1) if match else ""
        else:
            data["estacionamientos"] = ""
        print("estacionamientos:", data["estacionamientos"])
        time.sleep(0.05)
    else:
        data["tipo_propiedad"] = data["area_m2"] = data["recamaras"] = data["estacionamientos"] = ""
        print("tipo_propiedad:", data["tipo_propiedad"])
        print("area_m2:", data["area_m2"])
        print("recamaras:", data["recamaras"])
        print("estacionamientos:", data["estacionamientos"])
        time.sleep(0.05)

    # 2. Operaci√≥n, precio y mantenimiento
    price_container = soup.find("div", class_="price-container-property")
    if price_container:
        price_value_div = price_container.find("div", class_="price-value")
        if price_value_div:
            text = price_value_div.get_text(" ", strip=True)
            if "venta" in text.lower():
                data["operacion"] = "venta"
            elif "renta" in text.lower():
                data["operacion"] = "renta"
            else:
                data["operacion"] = ""
            print("operacion:", data["operacion"])
            time.sleep(0.05)

            span_precio = price_value_div.find("span")
            data["precio"] = span_precio.get_text(strip=True) if span_precio else ""
            print("precio:", data["precio"])
            time.sleep(0.05)
        else:
            data["operacion"] = data["precio"] = ""
            print("operacion:", data["operacion"])
            print("precio:", data["precio"])
            time.sleep(0.05)

        extra_div = price_container.find("div", class_="price-extra")
        if extra_div:
            span_mant = extra_div.find("span", class_="price-expenses")
            data["mantenimiento"] = span_mant.get_text(strip=True) if span_mant else ""
        else:
            data["mantenimiento"] = ""
        print("mantenimiento:", data["mantenimiento"])
        time.sleep(0.05)
    else:
        data["operacion"] = data["precio"] = data["mantenimiento"] = ""
        print("operacion:", data["operacion"])
        print("precio:", data["precio"])
        print("mantenimiento:", data["mantenimiento"])
        time.sleep(0.05)

    # 3. Direcci√≥n
    location_div = soup.find("div", class_="section-location-property")
    if location_div:
        h4 = location_div.find("h4")
        data["direccion"] = h4.get_text(strip=True) if h4 else ""
    else:
        data["direccion"] = ""
    print("direccion:", data["direccion"])
    time.sleep(0.05)

    # Extraer la URL del mapa est√°tico
    map_container = soup.find("div", class_="static-map-container")
    if map_container:
        img = map_container.find("img", id="static-map")
        if img:
            url = img.get("src", "")
            if url.startswith("//"):
                url = "https:" + url
            data["ubicacion_url"] = url
        else:
            data["ubicacion_url"] = ""
    else:
        data["ubicacion_url"] = ""
    print("ubicacion_url:", data["ubicacion_url"])
    time.sleep(0.05)

    # 4. T√≠tulo principal
    h1 = soup.find("h1", class_="title-property")
    data["titulo"] = h1.get_text(strip=True) if h1 else ""
    print("titulo:", data["titulo"])
    time.sleep(0.05)

    # 5. Descripci√≥n completa
    desc_section = soup.find("section", class_="article-section-description")
    if desc_section:
        long_desc = desc_section.find("div", id="longDescription")
        data["descripcion"] = long_desc.get_text(" ", strip=True) if long_desc else ""
    else:
        data["descripcion"] = ""
    print("descripcion:", data["descripcion"])
    time.sleep(0.05)

    # 7. Informaci√≥n del anunciante
    anunciante = soup.find("h3", attrs={"data-qa": "linkMicrositioAnunciante"})
    data["anunciante"] = anunciante.get_text(strip=True) if anunciante else ""
    print("anunciante:", data["anunciante"])
    time.sleep(0.05)

    # 8. C√≥digos del anuncio
    codes_section = soup.find("section", id="reactPublisherCodes")
    if codes_section:
        lis = codes_section.find_all("li")
        codigo_anunciante = ""
        codigo_inmuebles24 = ""
        for li in lis:
            text = li.get_text(" ", strip=True)
            if "C√≥d. del anunciante" in text:
                parts = text.split(":")
                codigo_anunciante = parts[1].strip() if len(parts) > 1 else ""
            elif "C√≥d. Inmuebles24" in text:
                parts = text.split(":")
                codigo_inmuebles24 = parts[1].strip() if len(parts) > 1 else ""
        data["codigo_anunciante"] = codigo_anunciante
        data["codigo_inmuebles24"] = codigo_inmuebles24
    else:
        data["codigo_anunciante"] = data["codigo_inmuebles24"] = ""
    print("codigo_anunciante:", data["codigo_anunciante"])
    time.sleep(0.05)
    print("codigo_inmuebles24:", data["codigo_inmuebles24"])
    time.sleep(0.05)

    # 9. Tiempo de publicaci√≥n
    user_views = soup.find("div", id="user-views")
    if user_views:
        p = user_views.find("p")
        data["tiempo_publicacion"] = p.get_text(strip=True) if p else ""
    else:
        data["tiempo_publicacion"] = ""
    print("tiempo_publicacion:", data["tiempo_publicacion"])
    time.sleep(0.05)

    # 10. Informaci√≥n del listado de iconos
    features_ul = soup.find("ul", id="section-icon-features-property")
    if features_ul:
        lis = features_ul.find_all("li", class_="icon-feature")
        data["area_total"] = ""
        data["area_cubierta"] = ""
        data["banos_icon"] = ""
        data["estacionamientos_icon"] = ""
        data["recamaras_icon"] = ""
        data["medio_banos_icon"] = ""
        data["antiguedad_icon"] = ""

        for li in lis:
            icon = li.find("i")
            if not icon:
                continue

            classes = icon.get("class", [])
            # Obtenemos el texto con un espacio en lugar de saltos de l√≠nea
            raw_text = li.get_text(" ", strip=True)

            # Opcional: unificar m√∫ltiples espacios en uno solo.
            # Esto NO elimina palabras como "ba√±os" ni hace replaces espec√≠ficos,
            # solo evita que haya muchos espacios o tabs.
            text = re.sub(r"\s+", " ", raw_text).strip()

            # DEBUG para ver qu√© valor se est√° capturando
            print("DEBUG => classes:", classes, "| text:", repr(text))

            # Asignamos a cada campo sin reemplazar nada espec√≠fico.
            if "icon-stotal" in classes:
                data["area_total"] = text
            elif "icon-scubierta" in classes:
                data["area_cubierta"] = text
            elif "icon-bano" in classes:
                data["banos_icon"] = text
            elif "icon-cochera" in classes:
                data["estacionamientos_icon"] = text
            elif "icon-dormitorio" in classes:
                data["recamaras_icon"] = text
            elif "icon-toilete" in classes:
                data["medio_banos_icon"] = text
            elif "icon-antiguedad" in classes:
                data["antiguedad_icon"] = text
    else:
        data["area_total"] = data["area_cubierta"] = data["banos_icon"] = ""
        data["estacionamientos_icon"] = data["recamaras_icon"] = data["medio_banos_icon"] = data["antiguedad_icon"] = ""

    print("area_total:", data["area_total"])
    time.sleep(0.05)
    print("area_cubierta:", data["area_cubierta"])
    time.sleep(0.05)
    print("banos_icon:", data["banos_icon"])
    time.sleep(0.05)
    print("estacionamientos_icon:", data["estacionamientos_icon"])
    time.sleep(0.05)
    print("recamaras_icon:", data["recamaras_icon"])
    time.sleep(0.05)
    print("medio_banos_icon:", data["medio_banos_icon"])
    time.sleep(0.05)
    #print("antiguedad_icon:", data["antiguedad_icon"])
    #time.sleep(0.05)

    return data


def extract_information_after_click(driver):
    info_botones = {}
    try:
        # Ubicar el contenedor principal
        container = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "reactGeneralFeatures"))
        )
        
        # Encontrar los botones dentro del contenedor
        buttons = container.find_elements(By.TAG_NAME, "button")
        print(f"üîé Se encontraron {len(buttons)} botones. Intentando extraer datos...\n")

        for button in buttons:
            try:
                span_btn = button.find_element(By.TAG_NAME, "span")
                button_text = span_btn.text.strip()
                print(f"‚û°Ô∏è Haciendo clic en: {button_text}")
                driver.execute_script("arguments[0].scrollIntoView(true);", button)
                time.sleep(0.5)
                driver.execute_script("arguments[0].click();", button)
                
                # Esperar hasta que el contenido aparezca despu√©s del clic
                try:
                    details_container = WebDriverWait(container, 5).until(
                        EC.presence_of_element_located((By.XPATH, ".//div[2]"))  # Usamos XPath para evitar clases cambiantes
                    )
                except:
                    print(f"‚ö†Ô∏è No se encontr√≥ el contenedor de detalles para '{button_text}'. Intentando otra estrategia...")
                    details_container = container.find_elements(By.TAG_NAME, "div")[1]  # Respaldo manual
                
                time.sleep(1)  # Pausa corta para asegurar que el contenido se despliegue

                # Extraer la informaci√≥n dentro del <span>
                features = [elem.text.strip() for elem in details_container.find_elements(By.TAG_NAME, "span") if elem.text.strip()]
                info_botones[button_text] = "; ".join(features)
                
                print(f"üìå Informaci√≥n extra√≠da de '{button_text}': {features}\n")

            except Exception as e:
                print(f"‚ùå No se pudo extraer informaci√≥n de '{button_text}': {e}\n")
    
    except Exception as e:
        print(f"‚ùå Error al buscar botones: {e}")
    
    return info_botones

def save(data_dict):
    today_str = dt.date.today().isoformat()
    out_dir = os.path.join(DDIR, today_str)
    os.makedirs(out_dir, exist_ok=True)
    fname = os.path.join(out_dir, "inmuebles24_terrenos_guadalajara_detalle.csv")

    df_new = pd.DataFrame([data_dict])
    try:
        df_existing = pd.read_csv(fname, encoding="utf-8")
    except FileNotFoundError:
        df_existing = pd.DataFrame()

    final_df = pd.concat([df_existing, df_new], ignore_index=True)

    # Reemplazar saltos de l√≠nea en todas las columnas por un espacio
    final_df = final_df.replace(r'[\r\n]+', ' ', regex=True)

    final_df.to_csv(fname, index=False, encoding="utf-8")
    print(f"Datos guardados en: {fname}")


def main():
    # Leer el archivo CSV que contiene las URLs en una columna "url"
    urls_df = pd.read_csv("data/2025-08-31/inmuebles24-zapopan-departamentos-venta.csv")
    urls = urls_df["url"].tolist()
    
    #for URL in urls:
    for i, URL in enumerate(urls, start=1):
        print(f"Iteraci√≥n {i} de {len(urls)}: {URL}")
        if "clasificado" not in URL:
            print(f"Saltando URL (no clasificado): {URL}")
            continue
        
        print(f"Navegando a: {URL}")
        
        # Iniciar el navegador dentro del bucle
        options = Options()
        options.add_argument("--headless")  # Modo headless habilitado
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        driver = webdriver.Chrome(options=options)
        driver.set_page_load_timeout(60)
        
        try:
            driver.get(URL)
            WebDriverWait(driver, 30).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "h2.title-type-sup-property"))
            )
            # Incrementar un poco el tiempo de espera para evitar bloqueos
            time.sleep(2)
            
            html = driver.page_source
            data = scrape_property_detail(driver, html)
            
            # Extraer informaci√≥n adicional mediante los botones
            botones_data = extract_information_after_click(driver)
            data.update(botones_data)
            
            # Guardar todos los datos en un √∫nico CSV
            save(data)
            
        except Exception as e:
            print(f"Error al cargar la p√°gina {URL}: {e}")
        
        finally:
            # Cerrar el navegador al terminar cada URL
            driver.quit()
        
        # Agregar un peque√±o retraso adicional antes de la siguiente URL
        time.sleep(2)

if __name__ == "__main__":
    main()



    """
    def extract_information_after_click(driver):
    info_botones = {}
    try:
        # Ubicar el contenedor principal
        container = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, "reactGeneralFeatures"))
        )
        
        # Encontrar los botones dentro del contenedor
        buttons = container.find_elements(By.TAG_NAME, "button")
        print(f"üîé Se encontraron {len(buttons)} botones. Intentando extraer datos...\n")

        for button in buttons:
            try:
                span_btn = button.find_element(By.TAG_NAME, "span")
                button_text = span_btn.text.strip()
                print(f"‚û°Ô∏è Haciendo clic en: {button_text}")
                driver.execute_script("arguments[0].scrollIntoView(true);", button)
                time.sleep(0.5)
                driver.execute_script("arguments[0].click();", button)
                
                # Esperar hasta que el contenido aparezca despu√©s del clic
                try:
                    details_container = WebDriverWait(container, 5).until(
                        EC.presence_of_element_located((By.XPATH, ".//div[2]"))  # Usamos XPath para evitar clases cambiantes
                    )
                except:
                    print(f"‚ö†Ô∏è No se encontr√≥ el contenedor de detalles para '{button_text}'. Intentando otra estrategia...")
                    details_container = container.find_elements(By.TAG_NAME, "div")[1]  # Respaldo manual
                
                time.sleep(1)  # Pausa corta para asegurar que el contenido se despliegue

                # Extraer la informaci√≥n dentro del <span>
                features = [elem.text.strip() for elem in details_container.find_elements(By.TAG_NAME, "span") if elem.text.strip()]
                info_botones[button_text] = "; ".join(features)
                
                print(f"üìå Informaci√≥n extra√≠da de '{button_text}': {features}\n")

            except Exception as e:
                print(f"‚ùå No se pudo extraer informaci√≥n de '{button_text}': {e}\n")
    
    except Exception as e:
        print(f"‚ùå Error al buscar botones: {e}")
    
    return info_botones"""